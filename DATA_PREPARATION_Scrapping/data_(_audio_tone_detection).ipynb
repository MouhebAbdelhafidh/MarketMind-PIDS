{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgu2nZmrew7z",
        "outputId": "f24cde6d-7006-45b0-ef02-ddc6a1b522d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo6MvJQKe8jK",
        "outputId": "9bdbcd67-b680-48a0-967b-e2a034079bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import whisper\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "mZ2T-Fwpe-_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Whisper model...\")\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbU4usjHfClQ",
        "outputId": "e7710b2c-2a70-48be-e6d8-90dca7c72554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:10<00:00, 46.9MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Emotions\"\n",
        "output_jsonl = \"/content/drive/MyDrive/Emotions_transcriptions.jsonl\""
      ],
      "metadata": {
        "id": "GDgDy9OXfEym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = []\n",
        "\n",
        "#  Walk through dataset folders\n",
        "print(\"Starting transcription...\")\n",
        "for emotion_folder in os.listdir(dataset_path):\n",
        "    emotion_path = os.path.join(dataset_path, emotion_folder)\n",
        "\n",
        "    if os.path.isdir(emotion_path):\n",
        "        for file in tqdm(os.listdir(emotion_path), desc=f\"Processing '{emotion_folder}'\"):\n",
        "            if file.endswith('.wav') or file.endswith('.mp3'):\n",
        "                audio_path = os.path.join(emotion_path, file)\n",
        "\n",
        "                try:\n",
        "                    result = model.transcribe(audio_path)\n",
        "                    transcription = result['text'].strip()\n",
        "                except Exception as e:\n",
        "                    print(f\"Error transcribing {audio_path}: {e}\")\n",
        "                    transcription = \"\"\n",
        "\n",
        "                # Save transcription + emotion\n",
        "                entry = {\n",
        "                    \"audio_path\": audio_path,\n",
        "                    \"transcription\": transcription,\n",
        "                    \"emotion\": emotion_folder\n",
        "                }\n",
        "                output_data.append(entry)\n",
        "\n",
        "#  Save results\n",
        "print(f\"Saving transcriptions to {output_jsonl}...\")\n",
        "with open(output_jsonl, 'w', encoding='utf-8') as f:\n",
        "    for item in output_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print(\"✅ Done! All transcriptions saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFTwp9N7fP3q",
        "outputId": "04953bde-c9bb-48fe-d800-d8c10d749d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting transcription...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing 'Disgusted': 100%|██████████| 1863/1863 [13:20<00:00,  2.33it/s]\n",
            "Processing 'Suprised': 100%|██████████| 592/592 [03:47<00:00,  2.61it/s]\n",
            "Processing 'Angry': 100%|██████████| 2177/2177 [18:01<00:00,  2.01it/s]\n",
            "Processing 'Neutral': 100%|██████████| 1795/1795 [13:46<00:00,  2.17it/s]\n",
            "Processing 'Sad': 100%|██████████| 2167/2167 [16:51<00:00,  2.14it/s]\n",
            "Processing 'Fearful': 100%|██████████| 2047/2047 [15:37<00:00,  2.18it/s]\n",
            "Processing 'Happy': 100%|██████████| 2167/2167 [16:36<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving transcriptions to /content/drive/MyDrive/Emotions_transcriptions.jsonl...\n",
            "✅ Done! All transcriptions saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}